# ðŸ’Ž ruby-spacy

## Overview 

**ruby-spacy** is a wrapper module for using [spaCy](https://spacy.io/) from the Ruby programming language via [PyCall](https://github.com/mrkn/pycall.rb). This module aims to make it easy and natural for Ruby programmers to use spaCy. This module covers the areas of spaCy functionality for _using_ many varieties of its language models, not for _building_ ones.

|    | Functionality                                      |
|:---|:---------------------------------------------------|
| âœ… | Tokenization, lemmatization, sentence segmentation |
| âœ… | Part-of-speech tagging and dependency parsing      |
| âœ… | Named entity recognition                           |
| âœ… | Syntactic dependency visualization                 |
| âœ… | Access to pre-trained word vectors                 |

## Installation of prerequisites

**IMPORTANT**: Make sure that the `enable-shared` option is enabled in your Python installation. You can use [pyenv](https://github.com/pyenv/pyenv) to install any version of Python you like. Install Python 3.10.6, for instance, using pyenv with `enable-shared` as follows:

```shell
$ env CONFIGURE_OPTS="--enable-shared" pyenv install 3.10.6
```

Remember to make it accessible from your working directory. It is recommended that you set `global` to the version of python you just installed.

```shell
$ pyenv global 3.10.6 
```

Then, install [spaCy](https://spacy.io/). If you use `pip`, the following command will do:

```shell
$ pip install spacy
```

Install trained language models. For a starter, `en_core_web_sm` will be the most useful to conduct basic text processing in English. However, if you want to use advanced features of spaCy, such as named entity recognition or document similarity calculation, you should also install a larger model like `en_core_web_lg`.


```shell
$ python -m spacy download en_core_web_sm
$ python -m spacy download en_core_web_lg
```

See [Spacy: Models & Languages](https://spacy.io/usage/models) for other models in various languages. To install models for the Japanese language, for instance, you can do it as follows:

```shell
$ python -m spacy download ja_core_news_sm
$ python -m spacy download ja_core_news_lg
```

## Installation of ruby-spacy

Add this line to your application's Gemfile:

```ruby
gem 'ruby-spacy'
```

And then execute:

    $ bundle install

Or install it yourself as:

    $ gem install ruby-spacy

## Usage

See [Examples](#examples) below.

## Examples

Many of the following examples are Python-to-Ruby translations of code snippets in [spaCy 101](https://spacy.io/usage/spacy-101). For more examples, look inside the `examples` directory.

### Tokenization

â†’ [spaCy: Tokenization](https://spacy.io/usage/spacy-101#annotations-token)

Ruby code: 

```ruby
require "ruby-spacy"
require "terminal-table"

nlp = Spacy::Language.new("en_core_web_sm")

doc = nlp.read("Apple is looking at buying U.K. startup for $1 billion")

row = []

doc.each do |token|
  row << token.text
end

headings = [1,2,3,4,5,6,7,8,9,10]
table = Terminal::Table.new rows: [row], headings: headings

puts table
```

Output:

| 1     | 2  | 3       | 4  | 5      | 6    | 7       | 8   | 9 | 10 | 11      |
|:-----:|:--:|:-------:|:--:|:------:|:----:|:-------:|:---:|:-:|:--:|:-------:|
| Apple | is | looking | at | buying | U.K. | startup | for | $ | 1  | billion |

### Part-of-speech and dependency

â†’ [spaCy: Part-of-speech tags and dependencies](https://spacy.io/usage/spacy-101#annotations-pos-deps)

Ruby code: 

```ruby
require "ruby-spacy"
require "terminal-table"

nlp = Spacy::Language.new("en_core_web_sm")
doc = nlp.read("Apple is looking at buying U.K. startup for $1 billion")

headings = ["text", "lemma", "pos", "tag", "dep"]
rows = []

doc.each do |token|
  rows << [token.text, token.lemma, token.pos, token.tag, token.dep]
end

table = Terminal::Table.new rows: rows, headings: headings
puts table
```

Output:

| text    | lemma   | pos   | tag | dep      |
|:--------|:--------|:------|:----|:---------|
| Apple   | Apple   | PROPN | NNP | nsubj    |
| is      | be      | AUX   | VBZ | aux      |
| looking | look    | VERB  | VBG | ROOT     |
| at      | at      | ADP   | IN  | prep     |
| buying  | buy     | VERB  | VBG | pcomp    |
| U.K.    | U.K.    | PROPN | NNP | dobj     |
| startup | startup | NOUN  | NN  | advcl    |
| for     | for     | ADP   | IN  | prep     |
| $       | $       | SYM   | $   | quantmod |
| 1       | 1       | NUM   | CD  | compound |
| billion | billion | NUM   | CD  | pobj     |

### Part-of-speech and dependency (Japanese)

Ruby code: 

```ruby
require "ruby-spacy"
require "terminal-table"

nlp = Spacy::Language.new("ja_core_news_lg")
doc = nlp.read("ä»»å¤©å ‚ã¯1983å¹´ã«ãƒ•ã‚¡ãƒŸã‚³ãƒ³ã‚’14,800å††ã§ç™ºå£²ã—ãŸã€‚")

headings = ["text", "lemma", "pos", "tag", "dep"]
rows = []

doc.each do |token|
  rows << [token.text, token.lemma, token.pos, token.tag, token.dep]
end

table = Terminal::Table.new rows: rows, headings: headings
puts table
```

Output:

| text       | lemma      | pos   | tag                      | dep    |
|:-----------|:-----------|:------|:-------------------------|:-------|
| ä»»å¤©å ‚     | ä»»å¤©å ‚     | PROPN | åè©ž-å›ºæœ‰åè©ž-ä¸€èˆ¬       | nsubj  |
| ã¯         | ã¯         | ADP   | åŠ©è©ž-ä¿‚åŠ©è©ž              | case   |
| 1983       | 1983       | NUM   | åè©ž-æ•°è©ž                | nummod |
| å¹´         | å¹´         | NOUN  | åè©ž-æ™®é€šåè©ž-åŠ©æ•°è©žå¯èƒ½ | obl    |
| ã«         | ã«         | ADP   | åŠ©è©ž-æ ¼åŠ©è©ž              | case   |
| ãƒ•ã‚¡ãƒŸã‚³ãƒ³ | ãƒ•ã‚¡ãƒŸã‚³ãƒ³ | NOUN  | åè©ž-æ™®é€šåè©ž-ä¸€èˆ¬       | obj    |
| ã‚’         | ã‚’         | ADP   | åŠ©è©ž-æ ¼åŠ©è©ž              | case   |
| 14,800     | 14,800     | NUM   | åè©ž-æ•°è©ž                | fixed  |
| å††         | å††         | NOUN  | åè©ž-æ™®é€šåè©ž-åŠ©æ•°è©žå¯èƒ½ | obl    |
| ã§         | ã§         | ADP   | åŠ©è©ž-æ ¼åŠ©è©ž              | case   |
| ç™ºå£²       | ç™ºå£²       | VERB  | åè©ž-æ™®é€šåè©ž-ã‚µå¤‰å¯èƒ½   | ROOT   |
| ã—         | ã™ã‚‹       | AUX   | å‹•è©ž-éžè‡ªç«‹å¯èƒ½          | aux    |
| ãŸ         | ãŸ         | AUX   | åŠ©å‹•è©ž                   | aux    |
| ã€‚         | ã€‚         | PUNCT | è£œåŠ©è¨˜å·-å¥ç‚¹            | punct  |

### Morphology 

â†’ [POS and morphology tags](https://github.com/explosion/spaCy/blob/master/spacy/glossary.py)

Ruby code:

```ruby
require "ruby-spacy"
require "terminal-table"

nlp = Spacy::Language.new("en_core_web_sm")
doc = nlp.read("Apple is looking at buying U.K. startup for $1 billion")

headings = ["text", "shape", "is_alpha", "is_stop", "morphology"]
rows = []

doc.each do |token|
  morph = token.morphology.map do |k, v|
    "#{k} = #{v}"
  end.join("\n")
  rows << [token.text, token.shape, token.is_alpha, token.is_stop, morph]
end

table = Terminal::Table.new rows: rows, headings: headings
puts table

```

Output:

| text    | shape | is_alpha | is_stop | morphology                                                                          |
|:--------|:------|:---------|:--------|:------------------------------------------------------------------------------------|
| Apple   | Xxxxx | true     | false   | NounType = Prop<br />Number = Sing                                                  |
| is      | xx    | true     | true    | Mood = Ind<br />Number = Sing<br />Person = 3<br />Tense = Pres<br />VerbForm = Fin |
| looking | xxxx  | true     | false   | Aspect = Prog<br />Tense = Pres<br />VerbForm = Part                                |
| at      | xx    | true     | true    |                                                                                     |
| buying  | xxxx  | true     | false   | Aspect = Prog<br />Tense = Pres<br />VerbForm = Part                                |
| U.K.    | X.X.  | false    | false   | NounType = Prop<br />Number = Sing                                                  |
| startup | xxxx  | true     | false   | Number = Sing                                                                       |
| for     | xxx   | true     | true    |                                                                                     |
| $       | $     | false    | false   |                                                                                     |
| 1       | d     | false    | false   | NumType = Card                                                                      |
| billion | xxxx  | true     | false   | NumType = Card                                                                      |

### Visualizing dependency

â†’ [spaCy: Visualizers](https://spacy.io/usage/visualizers)

Ruby code: 

```ruby
require "ruby-spacy"

nlp = Spacy::Language.new("en_core_web_sm")

sentence = "Autonomous cars shift insurance liability toward manufacturers"
doc = nlp.read(sentence)

dep_svg = doc.displacy(style: "dep", compact: false)

File.open(File.join("test_dep.svg"), "w") do |file|
  file.write(dep_svg)
end
```

Output:

![](https://github.com/yohasebe/ruby-spacy/blob/main/examples/get_started/outputs/test_dep.svg)

### Visualizing dependency (compact)

Ruby code: 

```ruby
require "ruby-spacy"

nlp = Spacy::Language.new("en_core_web_sm")

sentence = "Autonomous cars shift insurance liability toward manufacturers"
doc = nlp.read(sentence)

dep_svg = doc.displacy(style: "dep", compact: true)

File.open(File.join("test_dep_compact.svg"), "w") do |file|
  file.write(dep_svg)
end
```

Output:

![](https://github.com/yohasebe/ruby-spacy/blob/main/examples/get_started/outputs/test_dep_compact.svg)

### Named entity recognition

â†’ [spaCy: Named entities](https://spacy.io/usage/spacy-101#annotations-ner)

Ruby code: 

```ruby
require "ruby-spacy"
require "terminal-table"

nlp = Spacy::Language.new("en_core_web_sm")
doc =nlp.read("Apple is looking at buying U.K. startup for $1 billion")

rows = []

doc.ents.each do |ent|
  rows << [ent.text, ent.start_char, ent.end_char, ent.label]
end

headings = ["text", "start_char", "end_char", "label"]
table = Terminal::Table.new rows: rows, headings: headings
puts table
```

Output:

| text       | start_char | end_char | label |
|:-----------|-----------:|---------:|:------|
| Apple      | 0          | 5        | ORG   |
| U.K.       | 27         | 31       | GPE   |
| $1 billion | 44         | 54       | MONEY |

### Named entity recognition (Japanese)

Ruby code: 

```ruby
require( "ruby-spacy")
require "terminal-table"

nlp = Spacy::Language.new("ja_core_news_lg")

sentence = "ä»»å¤©å ‚ã¯1983å¹´ã«ãƒ•ã‚¡ãƒŸã‚³ãƒ³ã‚’14,800å††ã§ç™ºå£²ã—ãŸã€‚"
doc = nlp.read(sentence)

rows = []

doc.ents.each do |ent|
  rows << [ent.text, ent.start_char, ent.end_char, ent.label]
end

headings = ["text", "start", "end", "label"]
table = Terminal::Table.new rows: rows, headings: headings
print table
```

Output:

| text       | start | end | label   |
|:-----------|------:|----:|:--------|
| ä»»å¤©å ‚     | 0     | 3   | ORG     |
| 1983å¹´     | 4     | 9   | DATE    |
| ãƒ•ã‚¡ãƒŸã‚³ãƒ³ | 10    | 15  | PRODUCT |
| 14,800å††   | 16    | 23  | MONEY   |

### Checking availability of word vectors

â†’ [spaCy: Word vectors and similarity](https://spacy.io/usage/spacy-101#vectors-similarity)

Ruby code: 

```ruby
require "ruby-spacy"
require "terminal-table"

nlp = Spacy::Language.new("en_core_web_lg")
doc = nlp.read("dog cat banana afskfsd")

rows = []

doc.each do |token|
  rows << [token.text, token.has_vector, token.vector_norm, token.is_oov]
end

headings = ["text", "has_vector", "vector_norm", "is_oov"]
table = Terminal::Table.new rows: rows, headings: headings
puts table
```

Output:

| text    | has_vector | vector_norm | is_oov |
|:--------|:-----------|:------------|:-------|
| dog     | true       | 7.0336733   | false  |
| cat     | true       | 6.6808186   | false  |
| banana  | true       | 6.700014    | false  |
| afskfsd | false      | 0.0         | true   |

### Similarity calculation

Ruby code: 

```ruby
require "ruby-spacy"

nlp = Spacy::Language.new("en_core_web_lg")
doc1 = nlp.read("I like salty fries and hamburgers.")
doc2 = nlp.read("Fast food tastes very good.")

puts "Doc 1: " + doc1.text
puts "Doc 2: " + doc2.text
puts "Similarity: #{doc1.similarity(doc2)}"

```

Output:

```text
Doc 1: I like salty fries and hamburgers.
Doc 2: Fast food tastes very good.
Similarity: 0.7687607012190486
```

### Similarity calculation (Japanese)

Ruby code: 

```ruby
require "ruby-spacy"

nlp = Spacy::Language.new("ja_core_news_lg")
ja_doc1 = nlp.read("ä»Šæ—¥ã¯é›¨ã°ã£ã‹ã‚Šé™ã£ã¦ã€å«Œãªå¤©æ°—ã§ã™ã­ã€‚")
puts "doc1: #{ja_doc1.text}"
ja_doc2 = nlp.read("ã‚ã„ã«ãã®æ‚ªå¤©å€™ã§æ®‹å¿µã§ã™ã€‚")
puts "doc2: #{ja_doc2.text}"
puts "Similarity: #{ja_doc1.similarity(ja_doc2)}"
```

Output:

```text
doc1: ä»Šæ—¥ã¯é›¨ã°ã£ã‹ã‚Šé™ã£ã¦ã€å«Œãªå¤©æ°—ã§ã™ã­ã€‚
doc2: ã‚ã„ã«ãã®æ‚ªå¤©å€™ã§æ®‹å¿µã§ã™ã€‚
Similarity: 0.8684192637149641
```

### Word vector calculation

**Tokyo - Japan + France = Paris ?**

Ruby code: 

```ruby
require "ruby-spacy"
require "terminal-table"

nlp = Spacy::Language.new("en_core_web_lg")

tokyo = nlp.get_lexeme("Tokyo")
japan = nlp.get_lexeme("Japan")
france = nlp.get_lexeme("France")

query = tokyo.vector - japan.vector + france.vector

headings = ["rank", "text", "score"]
rows = []

results = nlp.most_similar(query, 10)
results.each_with_index do |lexeme, i|
  index = (i + 1).to_s
  rows << [index, lexeme.text, lexeme.score]
end

table = Terminal::Table.new rows: rows, headings: headings
puts table
```

Output:

| rank | text        | score              |
|:-----|:------------|:-------------------|
| 1    | FRANCE      | 0.8346999883651733 |
| 2    | France      | 0.8346999883651733 |
| 3    | france      | 0.8346999883651733 |
| 4    | PARIS       | 0.7703999876976013 |
| 5    | paris       | 0.7703999876976013 |
| 6    | Paris       | 0.7703999876976013 |
| 7    | TOULOUSE    | 0.6381999850273132 |
| 8    | Toulouse    | 0.6381999850273132 |
| 9    | toulouse    | 0.6381999850273132 |
| 10   | marseille   | 0.6370999813079834 |





### Word vector calculation (Japanese)

**æ±äº¬ - æ—¥æœ¬ + ãƒ•ãƒ©ãƒ³ã‚¹ = ãƒ‘ãƒª ?**

Ruby code: 

```ruby
require "ruby-spacy"
require "terminal-table"

nlp = Spacy::Language.new("ja_core_news_lg")

tokyo = nlp.get_lexeme("æ±äº¬")
japan = nlp.get_lexeme("æ—¥æœ¬")
france = nlp.get_lexeme("ãƒ•ãƒ©ãƒ³ã‚¹")

query = tokyo.vector - japan.vector + france.vector

headings = ["rank", "text", "score"]
rows = []

results = nlp.most_similar(query, 10)
results.each_with_index do |lexeme, i|
  index = (i + 1).to_s
  rows << [index, lexeme.text, lexeme.score]
end

table = Terminal::Table.new rows: rows, headings: headings
puts table
```

Output:

| rank | text           | score              |
|:-----|:---------------|:-------------------|
| 1    | ãƒ‘ãƒª           | 0.7376999855041504 |
| 2    | ãƒ•ãƒ©ãƒ³ã‚¹       | 0.7221999764442444 |
| 3    | æ±äº¬           | 0.6697999835014343 |
| 4    | ã‚¹ãƒˆãƒ©ã‚¹ãƒ–ãƒ¼ãƒ« | 0.631600022315979  |
| 5    | ãƒªãƒ¨ãƒ³         | 0.5939000248908997 |
| 6    | Paris          | 0.574400007724762  |
| 7    | ãƒ™ãƒ«ã‚®ãƒ¼       | 0.5683000087738037 |
| 8    | ãƒ‹ãƒ¼ã‚¹         | 0.5679000020027161 |
| 9    | ã‚¢ãƒ«ã‚¶ã‚¹       | 0.5644999742507935 |
| 10   | å—ä»           | 0.5547999739646912 |

## Author

Yoichiro Hasebe [<yohasebe@gmail.com>]


## Acknowlegments

I would like to thank the following open source projects and their creators for making this project possible:

- [explosion/spaCy](https://github.com/explosion/spaCy)
- [mrkn/pycall.rb](https://github.com/mrkn/pycall.rb)

## License

This library is available as open source under the terms of the [MIT License](https://opensource.org/licenses/MIT).
